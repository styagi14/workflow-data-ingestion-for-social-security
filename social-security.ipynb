{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account_name = \"social_support_user_details\"\n",
    "container_name = \"input\"\n",
    "mount_point = \"/mnt/datalake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_postgresql_path = f\"{mount_point}/raw/postgresql/users/\"\n",
    "raw_mongodb_path = f\"{mount_point}/raw/mongodb/attachments/\"\n",
    "processed_path = f\"{mount_point}/processed/enriched_user_data/\"\n",
    "analytics_path = f\"{mount_point}/analytics/user_metrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48efa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"OAuth\",\n",
    "  \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "  \"fs.azure.account.oauth2.client.id\": dbutils.secrets.get(scope=\"your-scope\", key=\"client-id\"),\n",
    "  \"fs.azure.account.oauth2.client.secret\": dbutils.secrets.get(scope=\"your-scope\", key=\"client-secret\"),\n",
    "  \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{dbutils.secrets.get(scope='your-scope', key='tenant-id')}/oauth2/token\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4769d39",
   "metadata": {},
   "source": [
    "# Read data from postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = spark.read.parquet(raw_postgresql_path)\n",
    "print(f\"Users count: {df_users.count()}\")\n",
    "df_users.printSchema()\n",
    "display(df_users.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e1c20",
   "metadata": {},
   "source": [
    "# Read data from mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d92627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attachments = spark.read.json(raw_mongodb_path)\n",
    "print(f\"Attachments count: {df_attachments.count()}\")\n",
    "df_attachments.printSchema()\n",
    "display(df_attachments.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de1126",
   "metadata": {},
   "source": [
    "## clean and transform user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_clean = df_users \\\n",
    "    .filter(col(\"user_id\").isNotNull()) \\\n",
    "    .withColumn(\"created_date\", to_date(col(\"created_at\"))) \\\n",
    "    .withColumn(\"full_name\", concat_ws(\" \", col(\"first_name\"), col(\"last_name\"))) \\\n",
    "    .withColumn(\"processed_timestamp\", current_timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83834de0",
   "metadata": {},
   "source": [
    "## Transform attachment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attachments_clean = df_attachments \\\n",
    "    .filter(col(\"user_id\").isNotNull()) \\\n",
    "    .withColumn(\"attachment_size_mb\", col(\"size\") / 1024 / 1024) \\\n",
    "    .withColumn(\"file_extension\", \n",
    "                regexp_extract(col(\"filename\"), r'\\.([^.]+)$', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233bf13d",
   "metadata": {},
   "source": [
    "## join user and attachment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched = df_users_clean.alias(\"u\") \\\n",
    "    .join(\n",
    "        df_attachments_clean.alias(\"a\"),\n",
    "        col(\"u.user_id\") == col(\"a.user_id\"),\n",
    "        \"left\"\n",
    "    ).select(\n",
    "        col(\"u.*\"),\n",
    "        col(\"a.attachment_id\"),\n",
    "        col(\"a.filename\"),\n",
    "        col(\"a.attachment_size_mb\"),\n",
    "        col(\"a.file_extension\"),\n",
    "        col(\"a.upload_date\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118eb06",
   "metadata": {},
   "source": [
    "## Write enriched data as delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9baebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .partitionBy(\"created_date\") \\\n",
    "    .save(processed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc3ac96",
   "metadata": {},
   "source": [
    "## Create Spark SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdb1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS enriched_user_data\n",
    "    USING DELTA\n",
    "    LOCATION '{processed_path}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa429960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48668027",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df_processed.select(\n",
    "    \"monthly_income\", \"years_of_experience\", \"family_size\",\n",
    "    \"total_assets\", \"total_liabilities\", \"age\", \"eligibility_label\"\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df[\"wealth_index\"] = pandas_df[\"total_assets\"] - pandas_df[\"total_liabilities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e466625",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pandas_df[[\"monthly_income\", \"years_of_experience\", \"family_size\", \"wealth_index\", \"age\"]]\n",
    "y = pandas_df[\"eligibility_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b995ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    \"monthly_income\": X_test[\"monthly_income\"],\n",
    "    \"prediction\": y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d28cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_spark = spark.createDataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_spark.write.format(\"delta\").mode(\"overwrite\").save(analytics_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
